{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Classification of Pima Indians Diabetes Data\n",
    "This project compares the performance of Naive Bayes, SVM, and Decision Trees on Pima Indians Diabetes Data. Naive Bayes and Decision Trees are coded \"from scratch\" with NumPy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Description\n",
    "\n",
    "The dataset 768 samples with the following features:\n",
    "1. Number of times pregnant\n",
    "2. Plasma glucose concentration from an oral glucose tolerance test\n",
    "3. Blood pressure (mmHg)\n",
    "4. Triceps skin fold thickness (mm)\n",
    "5. 2-hour serum insulin (mu U/ml)\n",
    "6. Body Mass Index\n",
    "7. Diabetes Pedigree Function\n",
    "8. Age\n",
    "9. Outcome: 0 or 1 (target variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import NaiveBayes\n",
    "import SVM\n",
    "import DecisionTree\n",
    "import DTscratch\n",
    "import datatools\n",
    "import crossvalidate\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Dataset:  768\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)}) # set the print format\n",
    "filename = \"pima-indians-diabetes.data.csv\"\n",
    "labels, features = datatools.loadDataset(filename)\n",
    "print(\"Size of Dataset: \",len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples with Diabetes:  268\n",
      "Number of Samples with No Diabetes:  500\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Samples with Diabetes: \", np.sum(labels == 1))\n",
    "print(\"Number of Samples with No Diabetes: \", np.sum(labels == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold Cross Validation with Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 out of 10\n",
      "Fold 2 out of 10\n",
      "Fold 3 out of 10\n",
      "Fold 4 out of 10\n",
      "Fold 5 out of 10\n",
      "Fold 6 out of 10\n",
      "Fold 7 out of 10\n",
      "Fold 8 out of 10\n",
      "Fold 9 out of 10\n",
      "Fold 10 out of 10\n",
      "Naive Bayes 10 fold CV accuracy: 65.10416666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prane\\PycharmProjects\\MLKit\\NaiveBayes.py:42: RuntimeWarning: invalid value encountered in true_divide\n",
      "  prob = prob/np.sum(prob)  # normalizing\n"
     ]
    }
   ],
   "source": [
    "CV_preds = crossvalidate.n_fold(features, labels, NaiveBayes, n_folds=10)\n",
    "print(\"Naive Bayes 10 fold CV accuracy:\", datatools.accuracy(labels, CV_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix and classification report after using Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[500   0]\n",
      " [268   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      1.00      0.79       500\n",
      "           1       0.00      0.00      0.00       268\n",
      "\n",
      "    accuracy                           0.65       768\n",
      "   macro avg       0.33      0.50      0.39       768\n",
      "weighted avg       0.42      0.65      0.51       768\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prane\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(labels, CV_preds))\n",
    "print(classification_report(labels,CV_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the confusion matrix and report, it is seen that the Naive Bayes classifier is unable to separate the classes, and classifies every sample as \"No Diabetes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold Cross Validation with SVM\n",
    "Let us see how the SVM performs using a linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 out of 10\n",
      "Fold 2 out of 10\n",
      "Fold 3 out of 10\n",
      "Fold 4 out of 10\n",
      "Fold 5 out of 10\n",
      "Fold 6 out of 10\n",
      "Fold 7 out of 10\n",
      "Fold 8 out of 10\n",
      "Fold 9 out of 10\n",
      "Fold 10 out of 10\n",
      "SVM 10 fold CV accuracy: 77.08333333333334\n"
     ]
    }
   ],
   "source": [
    "CV_preds = crossvalidate.n_fold(features, labels, SVM, 'linear', n_folds=10)\n",
    "print(\"SVM 10 fold CV accuracy:\", datatools.accuracy(labels, CV_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix and classification report after using SVM with a linear kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[439  61]\n",
      " [115 153]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.83       500\n",
      "           1       0.71      0.57      0.63       268\n",
      "\n",
      "    accuracy                           0.77       768\n",
      "   macro avg       0.75      0.72      0.73       768\n",
      "weighted avg       0.77      0.77      0.76       768\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(labels, CV_preds))\n",
    "print(classification_report(labels,CV_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the confusion matrix, it is seen that the SVM misclassifies 60 \"No Diabetes\" samples as \"Diabetes\" and 117 \"Diabetes\" samples as \"No Diabetes\". Overall, class separation is acheived with high precision and recall for predicting \"No Diabetes\". The false negative rate for \"Diabetes\" is a little high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see if using a non-linear kernel, radial basis function(RBF) improves performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 out of 10\n",
      "Fold 2 out of 10\n",
      "Fold 3 out of 10\n",
      "Fold 4 out of 10\n",
      "Fold 5 out of 10\n",
      "Fold 6 out of 10\n",
      "Fold 7 out of 10\n",
      "Fold 8 out of 10\n",
      "Fold 9 out of 10\n",
      "Fold 10 out of 10\n",
      "SVM 10 fold CV accuracy: 76.30208333333334\n"
     ]
    }
   ],
   "source": [
    "CV_preds = crossvalidate.n_fold(features, labels, SVM, 'rbf', n_folds=10)\n",
    "print(\"SVM 10 fold CV accuracy:\", datatools.accuracy(labels, CV_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix and classification report after using SVM with a RBF kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[455  45]\n",
      " [137 131]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.91      0.83       500\n",
      "           1       0.74      0.49      0.59       268\n",
      "\n",
      "    accuracy                           0.76       768\n",
      "   macro avg       0.76      0.70      0.71       768\n",
      "weighted avg       0.76      0.76      0.75       768\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(labels, CV_preds))\n",
    "print(classification_report(labels,CV_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using an RBF kernel improves classification of \"No Diabetes\", but more \"Diabetes\" samples are incorrectly classified than correctly classified. From this, it can be concluded that the linear kernel has better performance overall. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold Cross Validation with Decision Tree\n",
    "Let us see how the Decision Tree performs. The decision tree is set to have a max depth of 10 and a minimum of 5 samples before splitting a node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 out of 10\n",
      "Fold 2 out of 10\n",
      "Fold 3 out of 10\n",
      "Fold 4 out of 10\n",
      "Fold 5 out of 10\n",
      "Fold 6 out of 10\n",
      "Fold 7 out of 10\n",
      "Fold 8 out of 10\n",
      "Fold 9 out of 10\n",
      "Fold 10 out of 10\n",
      "Decision Tree 10 fold CV accuracy: 70.57291666666666\n"
     ]
    }
   ],
   "source": [
    "CV_preds = crossvalidate.n_fold(features, labels, DTscratch, 10, 5, n_folds=10)\n",
    "print(\"Decision Tree 10 fold CV accuracy:\", datatools.accuracy(labels, CV_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix and classification report after using a Decision Tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[386 114]\n",
      " [112 156]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.77      0.77       500\n",
      "           1       0.58      0.58      0.58       268\n",
      "\n",
      "    accuracy                           0.71       768\n",
      "   macro avg       0.68      0.68      0.68       768\n",
      "weighted avg       0.71      0.71      0.71       768\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(labels, CV_preds))\n",
    "print(classification_report(labels,CV_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Decision Tree acheives decent classification performance, but classification of \"No Diabetes\" is slightly worse that that of the SVM with a linear kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "From the algorithms compared above, the SVM with a linear kernel has the most optimal classification performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
